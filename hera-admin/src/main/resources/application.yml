spring:
    profiles:
        active: @env@
    monitor:
        path: /hera
        port: 8088
    http:
        multipart:
          max-file-size: 100Mb
          max-request-size: 100Mb
    freemarker:
      allow-request-override: true
      cache: false
      check-template-location: true
      charset: utf-8
      content-type: text/html
      expose-request-attributes: false
      expose-session-attributes: false
      expose-spring-macro-helpers: false
      suffix: .ftl
      template-loader-path: classpath:/templates/
      request-context-attribute: request

druid:
  datasource:
    username: twodfire  #数据库用户名
    password: 123456      #数据库密码
    driver-class-name: com.mysql.jdbc.Driver  #数据库驱动
    url: jdbc:mysql://common101.my.2dfire-daily.com:3306/lineage_db?useUnicode=true&amp;characterEncoding=utf-8&amp;zeroDateTimeBehavior=convertToNull&amp;autoReconnect=true&allowMultiQueries=true
    initial-size: 5    #初始化连接池数量
    min-idle: 1        #最小生存连接数
    max-active: 16     #最大连接池数量
    max-wait: 5000 #获取连接时最大等待时间，单位毫秒。配置了maxWait之后，缺省启用公平锁，并发效率会有所下降，如果需要可以通过配置useUnfairLock属性为true使用非公平锁。
    time-between-connect-error-millis: 60000  # Destroy线程会检测连接的间隔时间，如果连接空闲时间大于等于minEvictableIdleTimeMillis则关闭物理连接，单位是毫秒
    min-evictable-idle-time-millis: 300000  # 连接保持空闲而不被驱逐的最长时间，单位是毫秒
    test-while-idle: true    #申请连接的时候,如果检测到连接空闲时间大于timeBetweenEvictionRunsMillis，执行validationQuery检测连接是否有效
    test-on-borrow: true    #申请连接时执行validationQuery检测连接是否有效
    test-on-return: false   # 归还连接时执行validationQuery检测连接是否有效
    connection-init-sqls: set names utf8mb4
    validation-query: select 1                #用来检测连接是否有效的sql，要求是一个查询语句。如果validationQuery为null，testOnBorrow、testOnReturn、testWhileIdle都不会其作用。
    validation-query-timeout: 1                #单位：秒，检测连接是否有效的超时时间。底层调用jdbc Statement对象的void setQueryTimeout(int seconds)方法
    log-abandoned: true
    stat-mergeSql: true
    filters: stat,wall,log4j
    connection-properties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000

server:
  port: 8080
  context-path: /hera

clean:
   path: ${server.context-path}
#hera全局配置
hera:
   defaultWorkerGroup : 1 #默认worker的host组id
   preemptionMasterGroup : 1  #抢占master的host组id
   excludeFile: jar;war
   maxMemRate : 0.70       #已使用内存占总内存的最大比例,默认0.75
   maxCpuLoadPerCore : 1.0   #cpu load per core等于最近1分钟系统的平均cpu负载÷cpu核心数量，默认1.0
   scanRate : 1000        #队列扫描频率(毫秒)
   systemMemUsed : 4000  # 系统占用内存
   requestTimeout: 10000 # 异步请求超时时间
   channelTimeout: 1000 # netty请求超时时间
   perTaskUseMem : 500          # 每个任务使用内存500M
   heartBeat : 2           # 心跳传递时间频率
   workDir : /opt/logs/spring-boot1    # 工作路径  执行的任务文件/上传的文件都在这里
   hdfsUploadPath : /hera/hdfs-upload-dir/ #此处必须是hdfs路径，所有的上传附件都会存放在下面路径上.注意:必须保证启动hera项目的用户是此文件夹的所有者，否则会导致上传错误
   schedule-group : online
   maxParallelNum: 2000
   connectPort : 9887 #netty通信的端口
   admin: biadmin
   taskTimeout: 12  #单个任务执行的最大时间  单位：小时
   #hadoop 配置文件路径
   hadoop-home : /opt/cloudera/parcels/CDH/lib/hadoop
   hadoop-conf-dir : /etc/hadoop/conf
   hive-home : /opt/cloudera/parcels/CDH/lib/hive
   hive-conf-dir : /opt/cloudera/parcels/CDH/lib/hive/conf
   sqoop.home : /opt/cloudera/parcels/CDH/lib/sqoop
   spark-home : /home/hadoop/spark161-hadoop26
   env: @env@
mail:
  host: smtp.mxhichina.com
  protocol: smtp
  port: 465
  user: datacenter@2dfire.com
  password: 9c0af3

logging:
  config: classpath:logback-spring.xml
  path: /opt/logs/spring-boot   # 日志路径
  level:
    root: INFO
    org.springframework: ERROR
    com.dfire.common.mapper: ERROR


mybatis:
  configuration:
    mapUnderscoreToCamelCase: true
#spark 配置
spark :
  baseDir : /opt/app/spark231 #Spark基础路径
  address : jdbc:hive2://10.1.21.141:10000 #ThriftServer地址
  driver : org.apache.hive.jdbc.HiveDriver #jdbc driver
  username : heguozi #ThriftServer用户名
  password : 123456 #ThriftServer密码
  master : --master yarn
  driver-memory : --driver-memory 1g
  driver-cores : --driver-cores 1
  executor-memory : -- executor-memory 1g
  executor-cores : --executor-cores 1

---
spring:
  profiles: dev

logging:
  level:
    com.dfire.logs.ScheduleLog: ERROR
    com.dfire.logs.HeartLog: ERROR

---
spring:
  profiles: daily

---
spring:
  profiles: pre
druid:
  datasource:
    url: jdbc:mysql://rdsdb1101.my.2dfire-inc.com:3306/lineage?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull&amp;autoReconnect=true&allowMultiQueries=true
    username: lineage
    password: lineage@552208
#spark 配置
spark :
  baseDir : /opt/app/spark231 #Spark基础路径
  address : jdbc:hive2://spark-server001.2dfire-inc.com:10000 #ThriftServer地址
  master : --master yarn
  driver-memory : --driver-memory 2g
  driver-cores : --driver-cores 1
  executor-memory : -- executor-memory 2g
  executor-cores : --executor-cores 1
---
spring:
  profiles: publish
druid:
  datasource:
    url: jdbc:mysql://rdsdb1101.my.2dfire-inc.com:3306/lineage?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull&amp;autoReconnect=true&allowMultiQueries=true
    username: lineage
    password: lineage@552208
#spark 配置
spark :
  baseDir : /opt/app/spark231 #Spark基础路径
  address : jdbc:hive2://spark-server001.2dfire-inc.com:10000 #ThriftServer地址
  master : --master yarn
  driver-memory : --driver-memory 2g
  driver-cores : --driver-cores 1
  executor-memory : -- executor-memory 2g
  executor-cores : --executor-cores 1



---

## 此环境  不发邮件
spring:
  profiles: foreign
druid:
  datasource:
    url: jdbc:mysql://rdsdb1101.my.2dfire-inc.com:3306/lineage?useUnicode=true&amp;characterEncoding=UTF-8&amp;zeroDateTimeBehavior=convertToNull&amp;autoReconnect=true&allowMultiQueries=true
    username: lineage
    password: lineage@552208
#spark 配置
spark :
  address : jdbc:hive2://spark-server001.2dfire-inc.com:10000
  master : --master yarn
  driver-memory : --driver-memory 2g
  driver-cores : --driver-cores 1
  executor-memory : -- executor-memory 2g
  executor-cores : --executor-cores 1
